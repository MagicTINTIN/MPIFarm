\begin{lstlisting}[language=Python, style=jupycolors]
def quasiGradientDescent(positionsFixed, positionsFree, objectiveFunction, step=0.02, eps=1e-3, maxIter=1000):
    iter = 0
    objValOld = objectiveFunction(positionsFixed, positionsFree)
    objValNew = objValOld
    print("initial: ", objValOld)
    grad = quasiGradient(positionsFixed, positionsFree, objectiveFunction)
    while np.linalg.norm(grad) > eps and iter < maxIter and step > eps:
        grad = grad/np.linalg.norm(grad)
        print("grad", step, grad)
        positionsFree -= step * grad
        objValNew = objectiveFunction(positionsFixed, positionsFree) 
        if objValOld < objValNew:
            positionsFree += step * grad
            step = step * 0.9
        else:
            objValOld = objValNew
        grad = quasiGradient(positionsFixed, positionsFree, objectiveFunction)
        iter += 1
    print("iterations: ", iter,"/",maxIter)
    print("after optimization: ", objValNew)

    objectiveFunction(positionsFixed, positionsFree)
    visualization(positionsFixed, positionsFree, originalPositionsFree, True)

\end{lstlisting}